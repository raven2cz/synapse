# PLAN: AI Services Integration for Synapse

**Version:** v1.0.0
**Status:** âœ… PHASE 1 COMPLETE (2026-02-03)
**Created:** 2026-02-02
**Updated:** 2026-02-03
**Author:** raven2cz + Claude Opus 4.5
**Branch:** pack-edit

---

## Executive Summary

Synapse jako aplikace pro sprÃ¡vu AI modelÅ¯ by mÄ›la sama vyuÅ¾Ã­vat AI pro pokroÄilÃ© Ãºlohy.
UÅ¾ivatelÃ© Synapse jsou typicky AI enthusiasti s pÅ™Ã­stupem k rÅ¯znÃ½m AI sluÅ¾bÃ¡m
(Claude Max, Gemini Pro, lokÃ¡lnÃ­ Ollama). Tato infrastruktura umoÅ¾nÃ­ vyuÅ¾Ã­t tyto
sluÅ¾by pro automatizaci a inteligentnÃ­ funkce v rÃ¡mci Synapse.

**KlÃ­ÄovÃ© principy:**
- **Å½Ã¡dnÃ© API klÃ­Äe v aplikaci** - vyuÅ¾Ã­vÃ¡me CLI nÃ¡stroje s existujÃ­cÃ­mi subskripcemi uÅ¾ivatele
- **Graceful degradation** - vÅ¾dy existuje fallback (rule-based, manuÃ¡lnÃ­)
- **UÅ¾ivatel mÃ¡ kontrolu** - volÃ­ providery, priority, mÅ¯Å¾e vypnout AI ÃºplnÄ›
- **Task-specific priority** - rÅ¯znÃ© Ãºlohy mohou preferovat rÅ¯znÃ© providery

---

## 1. Use Cases pro AI v Synapse

### 1.1 AktuÃ¡lnÃ­ (Phase 1)

| Use Case | Popis | SloÅ¾itost | PreferovanÃ½ provider |
|----------|-------|-----------|---------------------|
| **Parameter Extraction** | Extrakce generaÄnÃ­ch parametrÅ¯ z description | StÅ™ednÃ­ | Ollama (rychlost) |

### 1.2 PlÃ¡novanÃ© (Phase 2+)

| Use Case | Popis | SloÅ¾itost | PreferovanÃ½ provider |
|----------|-------|-----------|---------------------|
| **Description Translation** | PÅ™eklad CN/JP/KR descriptions do EN | NÃ­zkÃ¡ | Ollama |
| **Auto-Tagging** | AutomatickÃ© tagovÃ¡nÃ­ modelÅ¯ podle description | NÃ­zkÃ¡ | Ollama |
| **Workflow Generation** | GenerovÃ¡nÃ­ ComfyUI workflow z parametrÅ¯ | VysokÃ¡ | Claude/Gemini |
| **Model Compatibility** | AnalÃ½za kompatibility LoRA + Checkpoint | StÅ™ednÃ­ | Gemini |
| **Preview Analysis** | AnalÃ½za stylu/kvality z preview obrÃ¡zkÅ¯ | VysokÃ¡ | Claude (multimodal) |
| **Smart Recommendations** | DoporuÄenÃ­ modelÅ¯ podle pouÅ¾itÃ­ | StÅ™ednÃ­ | Gemini |
| **Config Migration** | Konverze settings mezi UI (A1111 â†” ComfyUI) | VysokÃ¡ | Claude |

### 1.3 Task Complexity Categories

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Task Complexity Tiers                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TIER 1 (Low)     â”‚ Translation, Tagging, Simple extraction     â”‚
â”‚  Default: Ollama  â”‚ RychlÃ©, offline, Å¾Ã¡dnÃ© limity               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TIER 2 (Medium)  â”‚ Parameter extraction, Compatibility check   â”‚
â”‚  Default: Ollama  â”‚ Ollama s Gemini fallback                    â”‚
â”‚  â†’ Gemini         â”‚                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TIER 3 (High)    â”‚ Workflow generation, Config migration       â”‚
â”‚  Default: Gemini  â”‚ VyÅ¾aduje reasoning, kontext                 â”‚
â”‚  â†’ Claude         â”‚                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TIER 4 (Premium) â”‚ Image analysis, Complex multi-step tasks    â”‚
â”‚  Default: Claude  â”‚ Multimodal, nejvyÅ¡Å¡Ã­ kvalita                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. PodporovanÃ­ AI Providers

### 2.1 Provider Overview

| Provider | Typ | CLI pÅ™Ã­kaz | VÃ½hody | NevÃ½hody |
|----------|-----|------------|--------|----------|
| **Ollama** | LokÃ¡lnÃ­ | `ollama run <model>` | RychlÃ½ (2.9s), offline, neomezenÃ½ | VyÅ¾aduje GPU, obÄas halucinace |
| **Gemini CLI** | Cloud | `gemini -p` | NeomezenÃ½ s Pro, kvalitnÃ­ | PomalÃ½ (21s), vyÅ¾aduje internet |
| **Claude Code** | Cloud | `claude --print` | NejvyÅ¡Å¡Ã­ kvalita | OmezenÃ¡ kvÃ³ta (Max = tÃ½dennÃ­ limit) |

### 2.2 DoporuÄenÃ© modely

**Zdroj:** Benchmark testovÃ¡nÃ­ (viz [ai_extraction_spec.md](./ai_extraction_spec.md))

#### Ollama (lokÃ¡lnÃ­)
| Model | VRAM | Rychlost | Kvalita | PoznÃ¡mka |
|-------|------|----------|---------|----------|
| `qwen2.5:14b` â­ | ~9 GB | Ã˜ 2.9s | Ã˜ 10.1 klÃ­ÄÅ¯ | **DoporuÄenÃ½** - optimÃ¡lnÃ­ pomÄ›r |
| `qwen2.5:7b` | ~5 GB | ~2s | NiÅ¾Å¡Ã­ | Pro slabÅ¡Ã­ GPU, obÄas broken JSON |
| `llama3.1:8b` | ~6 GB | ~3s | StÅ™ednÃ­ | Alternativa k Qwen |
| `qwen2.5:32b` | ~18 GB | ~8s | VysokÃ¡ | Nevejde se do 16 GB VRAM |

#### Gemini CLI (cloud)
| Model | Rychlost | Kvalita | PoznÃ¡mka |
|-------|----------|---------|----------|
| `gemini-3-pro` â­ | Ã˜ 21s | Ã˜ 8.5 klÃ­ÄÅ¯ | **DoporuÄenÃ½** - vyÅ¾aduje Preview features |
| `gemini-3-flash` | ~10s | StÅ™ednÃ­ | RychlejÅ¡Ã­ varianta Gemini 3 |
| `gemini-3-deep-think` | ~60s | NejvyÅ¡Å¡Ã­ | Pro komplexnÃ­ reasoning |
| `gemini-2.5-pro` | ~20s | VysokÃ¡ | StabilnÃ­ GA fallback |
| `gemini-2.5-flash` | ~8s | StÅ™ednÃ­ | RychlÃ¡ varianta, niÅ¾Å¡Ã­ kvalita |

> âš ï¸ **PoznÃ¡mka:** Gemini 2.0 bude deprecated 3. bÅ™ezna 2026. Gemini 1.x jiÅ¾ nefunguje.

#### Claude Code (cloud)
| Model | Rychlost | Kvalita | PoznÃ¡mka |
|-------|----------|---------|----------|
| `claude-sonnet-4-20250514` â­ | Ã˜ 8.1s | Ã˜ 11.5 klÃ­ÄÅ¯ | **DoporuÄenÃ½** - nejvyÅ¡Å¡Ã­ kvalita |
| `claude-haiku-4-5-20251001` | ~3s | StÅ™ednÃ­ | RychlejÅ¡Ã­, Å¡etÅ™Ã­ kvÃ³tu |
| `claude-opus-4-5-20251101` | ~15s | NejvyÅ¡Å¡Ã­ | Overkill pro extrakci |

### 2.3 Detekce dostupnosti

PÅ™i startu aplikace automaticky detekovat:

```python
def detect_ai_providers() -> Dict[str, ProviderStatus]:
    """
    Detect which AI CLI tools are installed and accessible.

    Returns dict with:
    - available: bool - CLI tool exists
    - running: bool - service is running (Ollama)
    - models: List[str] - available models (Ollama)
    - version: str - CLI version
    """
```

| Provider | Detekce | DodateÄnÃ¡ kontrola |
|----------|---------|-------------------|
| Ollama | `which ollama` | `ollama list` pro dostupnÃ© modely |
| Gemini | `which gemini` | `gemini --version` |
| Claude | `which claude` | `claude --version` |

---

## 3. Settings UI Design

### 3.1 Main Settings Panel

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âš™ï¸ Settings                                              [Ã—]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                â”‚
â”‚  â”‚ ğŸ¤– AI       â”‚  General â”‚ Storage â”‚ UI â”‚ ...                  â”‚
â”‚  â”‚   Services  â”‚                                                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  AI Services                                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                 â”‚
â”‚  Enable AI-powered features    [â•â•â•â•â•â•â•â•â•â•â•â—‹] ON                â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Available Providers                                      â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  [âœ“] Ollama (Local)                        â— Running    â”‚   â”‚
â”‚  â”‚      Model: [qwen2.5:14b          â–¼]                    â”‚   â”‚
â”‚  â”‚      Endpoint: [http://localhost:11434    ]             â”‚   â”‚
â”‚  â”‚      Status: 3 models available                         â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  [âœ“] Gemini CLI (Cloud)                    â— Available  â”‚   â”‚
â”‚  â”‚      Model: [gemini-2.5-pro       â–¼]                    â”‚   â”‚
â”‚  â”‚      Preview features: [âœ“] Enabled                      â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  [ ] Claude Code (Cloud)                   â—‹ Available  â”‚   â”‚
â”‚  â”‚      Model: [claude-sonnet-4      â–¼]                    â”‚   â”‚
â”‚  â”‚      âš ï¸ Limited quota - use sparingly                   â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â”‚  â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€  â”‚   â”‚
â”‚  â”‚  âšª Rule-based (Fallback)                  â— Always ON  â”‚   â”‚
â”‚  â”‚      No AI required - pattern matching only             â”‚   â”‚
â”‚  â”‚                                                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  [Advanced Settings â–¼]                                          â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Advanced Settings (Expanded)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Advanced Settings                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                 â”‚
â”‚  Timeouts & Retries                                             â”‚
â”‚  â”œâ”€ CLI timeout (seconds):        [60        ]                  â”‚
â”‚  â”œâ”€ Max retries per provider:     [2         ]                  â”‚
â”‚  â””â”€ Retry delay (seconds):        [1         ]                  â”‚
â”‚                                                                 â”‚
â”‚  Caching                                                        â”‚
â”‚  â”œâ”€ Cache AI results:             [âœ“]                           â”‚
â”‚  â”œâ”€ Cache location:               ~/.synapse/store/data/cache/ai/â”‚
â”‚  â””â”€ Cache TTL (days):             [30        ]                  â”‚
â”‚                                                                 â”‚
â”‚  Fallback Behavior                                              â”‚
â”‚  â”œâ”€ Always fallback to rule-based: [âœ“]                          â”‚
â”‚  â””â”€ Show AI provider in results:   [âœ“]                          â”‚
â”‚                                                                 â”‚
â”‚  Logging                                                        â”‚
â”‚  â”œâ”€ Log AI requests:              [âœ“]                           â”‚
â”‚  â””â”€ Log level:                    [INFO      â–¼]                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.3 Task Priority Configuration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Task Priorities                                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                 â”‚
â”‚  Configure which providers to use for each task type.           â”‚
â”‚  Drag to reorder priority. Unchecked providers are skipped.     â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Parameter Extraction                          [Reset â†º] â”‚   â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”                                                   â”‚   â”‚
â”‚  â”‚ â”‚ â‰¡ â”‚ [âœ“] Ollama          qwen2.5:14b       ~3s        â”‚   â”‚
â”‚  â”‚ â”œâ”€â”€â”€â”¤                                                   â”‚   â”‚
â”‚  â”‚ â”‚ â‰¡ â”‚ [âœ“] Gemini          gemini-2.5-pro    ~20s       â”‚   â”‚
â”‚  â”‚ â”œâ”€â”€â”€â”¤                                                   â”‚   â”‚
â”‚  â”‚ â”‚ â‰¡ â”‚ [ ] Claude          claude-sonnet-4   ~8s        â”‚   â”‚
â”‚  â”‚ â””â”€â”€â”€â”˜                                                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Workflow Generation                           [Reset â†º] â”‚   â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”                                                   â”‚   â”‚
â”‚  â”‚ â”‚ â‰¡ â”‚ [âœ“] Gemini          gemini-2.5-pro    ~25s       â”‚   â”‚
â”‚  â”‚ â”œâ”€â”€â”€â”¤                                                   â”‚   â”‚
â”‚  â”‚ â”‚ â‰¡ â”‚ [âœ“] Claude          claude-sonnet-4   ~12s       â”‚   â”‚
â”‚  â”‚ â”œâ”€â”€â”€â”¤                                                   â”‚   â”‚
â”‚  â”‚ â”‚ â‰¡ â”‚ [ ] Ollama          qwen2.5:14b       ~5s        â”‚   â”‚
â”‚  â”‚ â””â”€â”€â”€â”˜                                                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Description Translation                       [Reset â†º] â”‚   â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”                                                   â”‚   â”‚
â”‚  â”‚ â”‚ â‰¡ â”‚ [âœ“] Ollama          qwen2.5:14b       ~2s        â”‚   â”‚
â”‚  â”‚ â”œâ”€â”€â”€â”¤                                                   â”‚   â”‚
â”‚  â”‚ â”‚ â‰¡ â”‚ [ ] Gemini          gemini-2.5-pro    ~15s       â”‚   â”‚
â”‚  â”‚ â””â”€â”€â”€â”˜                                                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  [Use Recommended Defaults]                                     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.4 Provider Not Available State

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [ ] Ollama (Local)                           â—‹ Not Installed   â”‚
â”‚      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚      Ollama is not installed on this system.                    â”‚
â”‚                                                                 â”‚
â”‚      Installation:                                              â”‚
â”‚      â€¢ Arch Linux: yay -S ollama-cuda                           â”‚
â”‚      â€¢ Ubuntu: curl -fsSL https://ollama.com/install.sh | sh    â”‚
â”‚      â€¢ macOS: brew install ollama                               â”‚
â”‚                                                                 â”‚
â”‚      After installation, run: ollama pull qwen2.5:14b           â”‚
â”‚                                                                 â”‚
â”‚      [ğŸ“– Documentation]  [ğŸ”„ Re-detect]                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Data Model

### 4.1 Design Principles

**Flexibilita pro budoucnost:**
- Providery identifikovanÃ© jako `str`, ne enum (snadnÃ© pÅ™idÃ¡vÃ¡nÃ­ novÃ½ch)
- Task types takÃ© `str` (novÃ© Ãºlohy bez zmÄ›ny kÃ³du)
- Registry pattern pro dynamickÃ© pÅ™idÃ¡vÃ¡nÃ­ providerÅ¯
- Backwards-compatible JSON schema

### 4.2 Settings Schema

```python
from dataclasses import dataclass, field
from typing import List, Optional, Dict, Any
from datetime import datetime

# NOTE: PouÅ¾Ã­vÃ¡me str mÃ­sto Enum pro flexibilitu
# NovÃ© providery/tasky lze pÅ™idat bez zmÄ›ny kÃ³du

# Well-known providers (pro UI hints, ale ne omezujÃ­cÃ­)
KNOWN_PROVIDERS = ["ollama", "gemini", "claude", "rule_based"]

# Well-known task types
KNOWN_TASKS = [
    "parameter_extraction",
    "description_translation",
    "auto_tagging",
    "workflow_generation",
    "model_compatibility",
    "preview_analysis",
    "config_migration",
]

@dataclass
class ProviderConfig:
    """Configuration for a single AI provider."""
    provider_id: str                      # e.g., "ollama", "gemini", "my_custom_provider"
    enabled: bool = False
    model: str = ""                       # Selected model
    available_models: List[str] = field(default_factory=list)  # Detected/configured models
    endpoint: Optional[str] = None        # Custom endpoint (Ollama)
    extra_args: Dict[str, Any] = field(default_factory=dict)  # Provider-specific settings

@dataclass
class TaskPriorityConfig:
    """Priority chain for a specific task type."""
    task_type: str                        # e.g., "parameter_extraction"
    provider_order: List[str] = field(default_factory=list)  # Provider IDs in order
    custom_timeout: Optional[int] = None  # Override global timeout for this task
    custom_prompt: Optional[str] = None   # Override default prompt template

@dataclass
class AIServicesSettings:
    """
    Complete AI services configuration.

    Stored in: settings.json under "ai_services" key
    """

    # Master switch
    enabled: bool = True

    # Provider configurations (key = provider_id)
    providers: Dict[str, ProviderConfig] = field(default_factory=dict)

    # Task-specific priorities (key = task_type)
    task_priorities: Dict[str, TaskPriorityConfig] = field(default_factory=dict)

    # Advanced settings
    cli_timeout_seconds: int = 60
    max_retries: int = 2
    retry_delay_seconds: int = 1

    # Caching
    cache_enabled: bool = True
    cache_ttl_days: int = 30
    cache_directory: str = "~/.synapse/store/data/cache/ai"

    # Behavior
    always_fallback_to_rule_based: bool = True
    show_provider_in_results: bool = True

    # Logging
    log_requests: bool = True
    log_level: str = "INFO"  # DEBUG, INFO, WARNING, ERROR
    log_prompts: bool = False  # Verbose: log full prompts
    log_responses: bool = False  # Verbose: log raw responses
```

### 4.2 Default Priorities

```python
DEFAULT_TASK_PRIORITIES: Dict[AITaskType, List[AIProvider]] = {
    # Tier 1 - Simple tasks, prefer local
    AITaskType.DESCRIPTION_TRANSLATION: [
        AIProvider.OLLAMA,
        AIProvider.GEMINI,
    ],
    AITaskType.AUTO_TAGGING: [
        AIProvider.OLLAMA,
        AIProvider.GEMINI,
    ],

    # Tier 2 - Medium complexity
    AITaskType.PARAMETER_EXTRACTION: [
        AIProvider.OLLAMA,
        AIProvider.GEMINI,
        AIProvider.CLAUDE,
    ],
    AITaskType.MODEL_COMPATIBILITY: [
        AIProvider.OLLAMA,
        AIProvider.GEMINI,
        AIProvider.CLAUDE,
    ],

    # Tier 3 - High complexity, prefer cloud
    AITaskType.WORKFLOW_GENERATION: [
        AIProvider.GEMINI,
        AIProvider.CLAUDE,
        AIProvider.OLLAMA,
    ],
    AITaskType.CONFIG_MIGRATION: [
        AIProvider.GEMINI,
        AIProvider.CLAUDE,
    ],

    # Tier 4 - Premium tasks
    AITaskType.PREVIEW_ANALYSIS: [
        AIProvider.CLAUDE,  # Multimodal required
        AIProvider.GEMINI,
    ],
}
```

### 4.3 Provider Status (Runtime)

```python
@dataclass
class ProviderStatus:
    """Runtime status of an AI provider."""
    provider: AIProvider
    available: bool = False          # CLI tool exists
    running: bool = False            # Service is running (Ollama)
    version: Optional[str] = None    # CLI version
    models: List[str] = field(default_factory=list)  # Available models
    error: Optional[str] = None      # Last error message
    last_check: Optional[datetime] = None
```

---

## 5. Backend Architecture

### 5.1 Prompt Management

**KRITICKÃ‰:** Prompty pro AI Ãºlohy jsou klÃ­ÄovÃ© pro kvalitu vÃ½stupu.

Pro **Parameter Extraction** pouÅ¾Ã­vÃ¡me **Prompt V2** z [ai_extraction_spec.md](./ai_extraction_spec.md):
- 10 pravidel optimalizovanÃ½ch na zÃ¡kladÄ› benchmarku
- snake_case enforcement
- Anti-grouping, anti-placeholder
- Base model guard (proti halucinacÃ­m)

```python
# src/ai/prompts/parameter_extraction.py

# Import prompt from spec - DO NOT MODIFY without re-benchmarking!
PARAMETER_EXTRACTION_PROMPT = """
You are an expert in AI image and video generation ecosystems...
[Full prompt from ai_extraction_spec.md Section 4.6]
"""

def build_extraction_prompt(description: str) -> str:
    """Build the full extraction prompt with description appended."""
    return f"{PARAMETER_EXTRACTION_PROMPT}\n\nDescription:\n{description}"
```

**Pravidla pro Ãºpravu promptÅ¯:**
1. JakÃ¡koliv zmÄ›na vyÅ¾aduje re-benchmark na testovacÃ­ sadÄ›
2. Dokumentovat zmÄ›ny s verzÃ­ (hash)
3. A/B testovat proti pÅ™edchozÃ­ verzi

### 5.3 Module Structure

```
src/
â”œâ”€â”€ ai/                           # NEW: AI services module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py              # Abstract base provider
â”‚   â”‚   â”œâ”€â”€ ollama.py            # Ollama provider
â”‚   â”‚   â”œâ”€â”€ gemini.py            # Gemini CLI provider
â”‚   â”‚   â”œâ”€â”€ claude.py            # Claude Code provider
â”‚   â”‚   â”œâ”€â”€ rule_based.py        # Fallback rule-based
â”‚   â”‚   â””â”€â”€ registry.py          # Provider registry (dynamic loading)
â”‚   â”‚
â”‚   â”œâ”€â”€ tasks/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py              # Abstract base task
â”‚   â”‚   â”œâ”€â”€ parameter_extraction.py
â”‚   â”‚   â”œâ”€â”€ description_translation.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ prompts/                  # Prompt templates
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ parameter_extraction.py  # V2 prompt from spec
â”‚   â”‚
â”‚   â”œâ”€â”€ service.py               # Main AI service (orchestrator)
â”‚   â”œâ”€â”€ cache.py                 # Result caching
â”‚   â”œâ”€â”€ detection.py             # Provider auto-detection
â”‚   â””â”€â”€ settings.py              # Settings management
â”‚
â””â”€â”€ utils/
    â””â”€â”€ parameter_extractor.py   # EXISTING: Keep as rule-based fallback
```

### 5.4 Provider Interface

```python
from abc import ABC, abstractmethod
from typing import Any, Dict, Optional

class AIProvider(ABC):
    """Abstract base class for AI providers."""

    @property
    @abstractmethod
    def name(self) -> str:
        """Provider identifier."""
        pass

    @property
    @abstractmethod
    def cli_command(self) -> str:
        """CLI command name (e.g., 'ollama', 'gemini', 'claude')."""
        pass

    @abstractmethod
    async def execute(
        self,
        prompt: str,
        model: str,
        timeout: int = 60,
    ) -> str:
        """
        Execute a prompt and return the raw response.

        Raises:
            ProviderNotAvailableError: CLI not installed
            ProviderTimeoutError: Execution timed out
            ProviderExecutionError: Non-zero exit code
        """
        pass

    @abstractmethod
    def detect_status(self) -> ProviderStatus:
        """Detect current provider status."""
        pass

    def parse_response(self, response: str) -> Dict[str, Any]:
        """
        Parse JSON response, stripping markdown fences if present.
        Default implementation - can be overridden.
        """
        text = response.strip()

        # Strip markdown code fences
        if text.startswith("```"):
            lines = text.split("\n")
            # Remove first line (```json or ```)
            lines = lines[1:]
            # Remove last line if it's closing fence
            if lines and lines[-1].strip() == "```":
                lines = lines[:-1]
            text = "\n".join(lines)

        return json.loads(text)
```

### 5.5 Task Interface

```python
from abc import ABC, abstractmethod
from typing import Any, Dict

class AITask(ABC):
    """Abstract base class for AI-powered tasks."""

    @property
    @abstractmethod
    def task_type(self) -> AITaskType:
        """Task type identifier."""
        pass

    @property
    @abstractmethod
    def default_priority(self) -> List[AIProvider]:
        """Default provider priority for this task."""
        pass

    @abstractmethod
    def build_prompt(self, input_data: Any) -> str:
        """Build the prompt for this task."""
        pass

    @abstractmethod
    def parse_result(self, raw_result: Dict[str, Any]) -> Any:
        """Parse and validate the AI response."""
        pass

    def get_cache_key(self, input_data: Any) -> str:
        """Generate cache key for input data."""
        return hashlib.sha256(str(input_data).encode()).hexdigest()[:16]
```

### 5.6 AI Service (Orchestrator)

```python
class AIService:
    """
    Main AI service - orchestrates providers and tasks.

    Handles:
    - Provider selection based on task priorities
    - Fallback chain execution
    - Result caching
    - Error handling and retries
    """

    def __init__(self, settings: AIServicesSettings):
        self.settings = settings
        self.providers: Dict[AIProvider, AIProviderBase] = {}
        self.cache = AICache(settings)
        self._init_providers()

    async def execute_task(
        self,
        task: AITask,
        input_data: Any,
        force_provider: Optional[AIProvider] = None,
    ) -> TaskResult:
        """
        Execute an AI task with fallback chain.

        Args:
            task: Task to execute
            input_data: Input data for the task
            force_provider: Override priority, use specific provider

        Returns:
            TaskResult with output and metadata
        """
        # Check cache first
        cache_key = task.get_cache_key(input_data)
        if cached := self.cache.get(task.task_type, cache_key):
            return cached

        # Build prompt
        prompt = task.build_prompt(input_data)

        # Get provider priority for this task
        priority = self._get_priority(task.task_type, force_provider)

        # Try each provider in order
        last_error = None
        for provider_type in priority:
            provider = self.providers.get(provider_type)
            if not provider or not self._is_provider_enabled(provider_type):
                continue

            try:
                raw_response = await provider.execute(
                    prompt=prompt,
                    model=self._get_model(provider_type),
                    timeout=self.settings.cli_timeout_seconds,
                )

                parsed = provider.parse_response(raw_response)
                result = task.parse_result(parsed)

                task_result = TaskResult(
                    success=True,
                    output=result,
                    provider=provider_type,
                    cached=False,
                )

                # Cache successful result
                self.cache.set(task.task_type, cache_key, task_result)

                return task_result

            except Exception as e:
                last_error = e
                logger.warning(f"Provider {provider_type} failed: {e}")
                continue

        # All providers failed - try rule-based fallback
        if self.settings.always_fallback_to_rule_based:
            try:
                fallback = self.providers[AIProvider.RULE_BASED]
                result = await fallback.execute_task(task, input_data)
                return TaskResult(
                    success=True,
                    output=result,
                    provider=AIProvider.RULE_BASED,
                    cached=False,
                )
            except Exception as e:
                last_error = e

        # Complete failure
        return TaskResult(
            success=False,
            error=str(last_error),
            provider=None,
        )
```

---

## 6. API Endpoints

### 6.1 Settings API

```python
# GET /api/settings/ai
# Returns current AI settings + provider status

@router.get("/settings/ai")
def get_ai_settings() -> AISettingsResponse:
    """
    Get AI services settings and current provider status.

    Returns:
        settings: Current AIServicesSettings
        provider_status: Dict of ProviderStatus for each provider
    """

# PATCH /api/settings/ai
# Update AI settings

@router.patch("/settings/ai")
def update_ai_settings(update: AISettingsUpdate) -> AISettingsResponse:
    """Update AI services settings."""

# POST /api/settings/ai/detect
# Re-detect available providers

@router.post("/settings/ai/detect")
def detect_providers() -> Dict[str, ProviderStatus]:
    """Re-detect available AI providers."""

# POST /api/settings/ai/test/{provider}
# Test a specific provider

@router.post("/settings/ai/test/{provider}")
def test_provider(provider: str) -> ProviderTestResult:
    """Test a specific provider with a simple prompt."""
```

### 6.2 Task Execution API

```python
# POST /api/ai/extract-parameters
# Extract parameters using AI

@router.post("/ai/extract-parameters")
async def extract_parameters(
    request: ParameterExtractionRequest,
) -> ParameterExtractionResponse:
    """
    Extract generation parameters from description using AI.

    Request:
        description: str - Model description (may contain HTML)
        force_provider: Optional[str] - Override default priority

    Response:
        parameters: Dict[str, Any] - Extracted parameters
        provider: str - Which provider was used
        cached: bool - Whether result was from cache
        confidence: float - Extraction confidence (0-1)
    """
```

---

## 7. Frontend Components

### 7.1 Component Structure

```
apps/web/src/
â”œâ”€â”€ components/
â”‚   â””â”€â”€ modules/
â”‚       â””â”€â”€ settings/
â”‚           â”œâ”€â”€ AIServicesSettings.tsx      # Main settings panel
â”‚           â”œâ”€â”€ ProviderCard.tsx            # Single provider config
â”‚           â”œâ”€â”€ TaskPriorityConfig.tsx      # Task priority editor
â”‚           â”œâ”€â”€ ProviderStatusBadge.tsx     # Status indicator
â”‚           â””â”€â”€ ProviderInstallGuide.tsx    # Installation help
â”‚
â”œâ”€â”€ hooks/
â”‚   â”œâ”€â”€ useAISettings.ts                    # Settings management
â”‚   â”œâ”€â”€ useProviderStatus.ts                # Provider status polling
â”‚   â””â”€â”€ useAITask.ts                        # Task execution
â”‚
â””â”€â”€ lib/
    â””â”€â”€ ai/
        â”œâ”€â”€ types.ts                        # TypeScript types
        â””â”€â”€ api.ts                          # API client
```

### 7.2 TypeScript Types

```typescript
// lib/ai/types.ts

// FlexibilnÃ­ typy - string mÃ­sto enum pro rozÅ¡iÅ™itelnost
export type ProviderId = string  // "ollama" | "gemini" | "claude" | custom
export type TaskType = string    // "parameter_extraction" | custom

// Well-known providers (for UI hints)
export const KNOWN_PROVIDERS = ['ollama', 'gemini', 'claude', 'rule_based'] as const
export const KNOWN_TASKS = [
  'parameter_extraction',
  'description_translation',
  'auto_tagging',
  'workflow_generation',
  'model_compatibility',
  'preview_analysis',
  'config_migration',
] as const

export interface ProviderConfig {
  providerId: string
  enabled: boolean
  model: string
  availableModels: string[]
  endpoint?: string
  extraArgs?: Record<string, unknown>
}

export interface ProviderStatus {
  providerId: string
  available: boolean
  running: boolean
  version?: string
  models: string[]
  error?: string
  lastCheck?: string
}

export interface TaskPriorityConfig {
  taskType: string
  providerOrder: string[]  // Provider IDs
  customTimeout?: number
  customPrompt?: string
}

export interface AIServicesSettings {
  enabled: boolean
  providers: Record<string, ProviderConfig>
  taskPriorities: Record<string, TaskPriorityConfig>
  cliTimeoutSeconds: number
  maxRetries: number
  retryDelaySeconds: number
  cacheEnabled: boolean
  cacheTtlDays: number
  cacheDirectory: string
  alwaysFallbackToRuleBased: boolean
  showProviderInResults: boolean
  logRequests: boolean
  logLevel: 'DEBUG' | 'INFO' | 'WARNING' | 'ERROR'
  logPrompts: boolean
  logResponses: boolean
}

export interface TaskResult<T = unknown> {
  success: boolean
  output?: T
  error?: string
  provider?: string
  cached: boolean
  executionTimeMs?: number
}

// Extraction specific
export interface ParameterExtractionResult {
  parameters: Record<string, unknown>
  extractedBy: string  // Provider ID
  confidence?: number
  rawKeys?: string[]   // Original keys before normalization
}
```

---

## 8. Implementation Phases

### Phase 1: Foundation âœ… COMPLETE (2026-02-03)
**Goal:** Basic infrastructure + Parameter Extraction + Integration + Full Settings UI

**KlÃ­ÄovÃ© vÃ½stupy:**
- âœ… AutomatickÃ¡ extrakce parametrÅ¯ pÅ™i Civitai importu
- âœ… Fallback chain: `ollama â†’ gemini â†’ claude â†’ rule_based`
- âœ… Ollama auto-start/stop pro sprÃ¡vu VRAM
- âœ… Cache s SHA-256[:16] klÃ­Äem
- âœ… `_extracted_by` badge v PackParametersSection
- âœ… Settings UI dle spec 3.1-3.4 (viz 8.1.5)
- âœ… 72 testÅ¯ prochÃ¡zÃ­

---

#### 8.1.1 Backend: AI Module âœ… COMPLETE (2026-02-02)

| Soubor | Stav | Popis |
|--------|------|-------|
| `src/ai/__init__.py` | âœ… | HlavnÃ­ exporty |
| `src/ai/providers/base.py` | âœ… | Abstract provider + JSON fence stripping |
| `src/ai/providers/ollama.py` | âœ… | `ollama run <model> <prompt>` |
| `src/ai/providers/gemini.py` | âœ… | `gemini --model <model> -p <prompt>` |
| `src/ai/providers/claude.py` | âœ… | `claude --print --model <model> <prompt>` |
| `src/ai/providers/rule_based.py` | âœ… | Wrapper pro stÃ¡vajÃ­cÃ­ `parameter_extractor.py` |
| `src/ai/providers/registry.py` | âœ… | DynamickÃ¡ registrace providerÅ¯ |
| `src/ai/service.py` | âœ… | Orchestrator s fallback chain |
| `src/ai/cache.py` | âœ… | SHA-256[:16] cache s TTL |
| `src/ai/detection.py` | âœ… | Auto-detect providerÅ¯ |
| `src/ai/settings.py` | âœ… | DatovÃ© modely (str mÃ­sto enum) |
| `src/ai/prompts/parameter_extraction.py` | âœ… | Prompt V2 (10 pravidel) |
| `src/ai/tasks/base.py` | âœ… | Task interface |
| `src/ai/tasks/parameter_extraction.py` | âœ… | Extraction task |

**Testy:** 63 testÅ¯ (28 providers + 14 cache + 21 service)

---

#### 8.1.2 Backend: API Endpoints âœ… COMPLETE

PÅ™idÃ¡no do `src/store/api.py` (`ai_router`):

| Endpoint | Metoda | Popis |
|----------|--------|-------|
| `/api/ai/providers` | GET | Detekce dostupnÃ½ch providerÅ¯ |
| `/api/ai/extract` | POST | Extrakce parametrÅ¯ (standalone) |
| `/api/ai/cache/stats` | GET | Statistiky cache |
| `/api/ai/cache` | DELETE | VyÄiÅ¡tÄ›nÃ­ cache |
| `/api/ai/cache/cleanup` | POST | Cleanup expirovanÃ½ch |
| `/api/ai/settings` | GET | AktuÃ¡lnÃ­ nastavenÃ­ |

---

#### 8.1.3 Backend: Integrace do Import Flow âœ… COMPLETE (2026-02-03)

**AutomatickÃ¡ extrakce pÅ™i Civitai importu funguje!**

| Ãškol | Stav | Soubor | Popis |
|------|------|--------|-------|
| Napojit AIService na import | âœ… | `src/store/pack_service.py:544` | PouÅ¾it `AIService.extract_parameters()` |
| PÅ™idat `_extracted_by` do vÃ½sledku | âœ… | `src/ai/service.py:216` | PÅ™idÃ¡vÃ¡ provider ID do vÃ½stupu |
| UloÅ¾it provider info do pack | âœ… | `src/store/models.py` | Pole `parameters_source` + `_extracted_by` |
| Ollama auto-start/stop | âœ… | `src/ai/providers/ollama.py` | Auto-start `ollama serve`, auto-stop po extrakci |
| AI Response normalizace | âœ… | `src/store/models.py:500-586` | Normalizuje AI formÃ¡t (listy, ranges, resolution) |

**Ollama lifecycle management:**
```python
# src/ai/providers/ollama.py
class OllamaProvider(AIProvider):
    def __init__(self, auto_start_server=True, auto_stop_server=True):
        # Automaticky spouÅ¡tÃ­ ollama serve pokud nebÄ›Å¾Ã­
        # Automaticky zastavuje po extrakci (uvolnÃ­ VRAM)

    def _start_server(self) -> bool:
        # SpustÃ­ ollama serve v background
        # ÄŒekÃ¡ max 30s na ready

    def _stop_server(self) -> None:
        # ZastavÃ­ server pouze pokud jsme ho my spustili
```

**atexit cleanup:**
```python
# RegistrovÃ¡n cleanup handler pro pÅ™Ã­pad ukonÄenÃ­ aplikace
atexit.register(_cleanup_server)
```

---

#### 8.1.4 Backend: Opravy âœ… COMPLETE

| Ãškol | Stav | Popis |
|------|------|-------|
| Gemini model name | âœ… | ZmÄ›nÄ›no na `gemini-3-pro-preview` (ovÄ›Å™eno - `gemini-3-pro` vracÃ­ 404) |
| PÅ™idat `_extracted_by` | âœ… | Do vÃ½stupu pÅ™idÃ¡n provider ID (dle spec 4.5) |
| Zachovat VÅ ECHNY AI fields | âœ… | Normalizace NEmaÅ¾e Å¾Ã¡dnÃ¡ pole - AI Notes se uklÃ¡dajÃ­ |

---

#### 8.1.5 Frontend: Settings UI âœ… COMPLETE (2026-02-03)

| Komponenta | Stav | Popis |
|------------|------|-------|
| `AIServicesSettings.tsx` | âœ… | HlavnÃ­ panel dle spec 3.1 - master switch, provider cards, cache |
| `ProviderCard.tsx` | âœ… | Enable/disable, model dropdown, endpoint input (Ollama) |
| `AdvancedAISettings.tsx` | âœ… | Spec 3.2 - timeouts, retries, cache TTL, logging |
| `TaskPriorityConfig.tsx` | âœ… | Spec 3.3 - drag & drop provider reordering |
| `StatusBadge` (inline) | âœ… | Running/Available/Not Installed |
| `InstallationGuide` | âœ… | Spec 3.4 - installation instructions per provider |
| `useAIProviders` | âœ… | Hook pro detekci providerÅ¯ |
| `useAISettings` | âœ… | Hook pro settings (GET) |
| `useUpdateAISettings` | âœ… | Hook pro settings (PATCH) |
| `useAICacheStats` | âœ… | Hook pro cache statistiky |
| TypeScript typy | âœ… | `apps/web/src/lib/ai/types.ts` |

**API Endpoints (novÃ©):**
- âœ… `PATCH /api/ai/settings` - Update AI settings

**ImplementovÃ¡no dle specifikace:**
- âœ… Spec 3.1 - Main Settings Panel (master switch, provider enable/disable, model dropdown, endpoint)
- âœ… Spec 3.2 - Advanced Settings (timeouts, retries, cache TTL, logging)
- âœ… Spec 3.3 - Task Priority Config (drag & drop reordering)
- âœ… Spec 3.4 - Provider Not Available state (installation instructions per platform)

---

#### 8.1.6 Frontend: Integration âœ… COMPLETE

| Ãškol | Stav | Popis |
|------|------|-------|
| Zobrazit `_extracted_by` v UI | âœ… | Badge s Bot ikonou v PackParametersSection |
| Settings v navigaci | âœ… | AI Services sekce v SettingsPage |
| Typy v pack-detail | âœ… | `_extracted_by`, `parameters_source` v types.ts |

---

#### 8.1.7 Phase 1 Checklist âœ… COMPLETE

**Backend Infrastructure:** âœ… COMPLETE
- [x] AI module structure
- [x] All 4 providers (Ollama, Gemini, Claude, Rule-based)
- [x] Service orchestrator with fallback
- [x] Caching system (SHA-256[:16], TTL 30 days)
- [x] Provider detection
- [x] Prompt V2 (10 pravidel)
- [x] API endpoints (7 endpointÅ¯ vÄetnÄ› PATCH /settings)
- [x] Unit tests (63 testÅ¯)

**Backend Integration:** âœ… COMPLETE
- [x] **Integrate AIService into Civitai import flow** âœ…
- [x] Add `_extracted_by` to results âœ…
- [x] Fix Gemini model name (`gemini-3-pro-preview`) âœ…
- [x] Ollama auto-start/stop (VRAM management) âœ…
- [x] AI Response normalization (lists, ranges, resolution) âœ…
- [x] Preserve ALL AI fields (compatibility, usage_tips, etc.) âœ…
- [x] **ai_router connected in main.py** âœ… (2026-02-03 fix)

**Frontend:** âœ… COMPLETE (2026-02-03)
- [x] AIServicesSettings component âœ…
- [x] ProviderCard component âœ…
- [x] AdvancedAISettings component âœ…
- [x] TaskPriorityConfig component âœ…
- [x] useAIProviders, useAISettings, useAICacheStats hooks âœ…
- [x] useUpdateAISettings hook âœ…
- [x] Display `_extracted_by` badge in UI âœ…
- [x] Settings navigation (AI Services sekce) âœ…
- [x] TypeScript typy âœ…
- [x] **Enable/disable per provider** âœ… (spec 3.1)
- [x] **Model dropdown per provider** âœ… (spec 3.1)
- [x] **Endpoint input (Ollama)** âœ… (spec 3.1)
- [x] **Advanced Settings accordion** âœ… (spec 3.2)
- [x] **Task Priority Config (drag & drop)** âœ… (spec 3.3)
- [x] **Provider Not Available state** âœ… (spec 3.4)
- [x] **Settings PATCH API + persistence** âœ…

**Tests:** âœ… COMPLETE
- [x] 72 AI-related tests pass âœ…
- [x] TypeScript compilation passes âœ…

---

#### 8.1.8 AI Insights vs Custom Parameters - ARCHITECTURE FIX âœ… COMPLETE (2026-02-03)

**Status:** âœ… OPRAVENO - AI Insights a Custom Parameters jsou nynÃ­ oddÄ›lenÃ©

**Commits:**
- `c4b606c` - fix: Properly separate AI Insights from Custom Parameters
- `8285740` - fix: Resolve button nesting DOM warning in EditParametersModal
- `90c506e` - fix: Keep user custom params visible in EditParametersModal

---

##### PROBLEM ANALYSIS

**HlavnÃ­ problÃ©m:** AI Insights jsou NESPRÃVNÄš kategorizovÃ¡ny jako 'custom' a nelze rozliÅ¡it od user custom params.

**Root cause:** PouÅ¾Ã­vali jsme pouze `_extracted_by` boolean pro rozliÅ¡enÃ­, ale to oznaÄuje celÃ½ pack, ne jednotlivÃ¡ pole.

**DÅ¯sledky:**
1. AI Insights (usage_tips, compatibility, recommended_embeddings...) â†’ `category = 'custom'`
2. User-defined custom params â†’ `category = 'custom'`
3. Nelze je rozliÅ¡it!
4. V EditParametersModal se AI notes mÃ­sÃ­ s user custom params
5. PÅ™i uloÅ¾enÃ­ dochÃ¡zÃ­ ke ztrÃ¡tÄ› nebo pÅ™episovÃ¡nÃ­ dat

---

##### IMPLEMENTED SOLUTION âœ…

**KlÃ­ÄovÃ½ princip:** Trackovat jednotlivÃ¡ AI-extrahovanÃ¡ pole pomocÃ­ `_ai_fields` array, ne pouze pack-level `_extracted_by`.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DATA FLOW - Parameter Types (IMPLEMENTED)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Backend (src/ai/service.py):                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  AI extraction output:                                   â”‚   â”‚
â”‚  â”‚  {                                                       â”‚   â”‚
â”‚  â”‚    "cfg_scale": 7,           â† AI-extracted, KNOWN       â”‚   â”‚
â”‚  â”‚    "usage_tips": "...",      â† AI-extracted, UNKNOWN     â”‚   â”‚
â”‚  â”‚    "_extracted_by": "gemini", â† Provider ID              â”‚   â”‚
â”‚  â”‚    "_ai_fields": ["cfg_scale", "usage_tips", ...]        â”‚   â”‚
â”‚  â”‚  }                            â†‘ NEW! Tracks AI fields    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  Frontend decision logic:                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  For each field:                                         â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  isAiField = _ai_fields.includes(key)                    â”‚   â”‚
â”‚  â”‚  isKnownParam = PARAM_CATEGORIES contains key            â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  if (isAiField && isKnownParam)     â†’ Show in category   â”‚   â”‚
â”‚  â”‚  if (isAiField && !isKnownParam)    â†’ AI Insights only   â”‚   â”‚
â”‚  â”‚  if (!isAiField && !isKnownParam)   â†’ Custom Parameters  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**KlÃ­ÄovÃ© principy implementace:**

1. **`_ai_fields`** = array of field names that came from AI extraction
2. **AI Insights** = fields in `_ai_fields` that are NOT in `PARAM_CATEGORIES`
3. **Custom Parameters** = fields NOT in `_ai_fields` and NOT in `PARAM_CATEGORIES`
4. **Known params** = fields in `PARAM_CATEGORIES` (regardless of source)

---

##### ACTUAL IMPLEMENTATION âœ…

**1. Backend: `src/ai/service.py` - Add `_ai_fields` tracking**

```python
# src/ai/service.py:216 (in execute_task method)
# Add _extracted_by to output if configured (per spec 4.5)
if self.settings.show_provider_in_results and isinstance(parsed, dict):
    parsed["_extracted_by"] = result.provider_id
    # Track which fields came from AI (for distinguishing from user custom fields)
    parsed["_ai_fields"] = [k for k in parsed.keys() if not k.startswith("_")]
```

**ProÄ:** `_ai_fields` je array nÃ¡zvÅ¯ polÃ­, kterÃ¡ pÅ™iÅ¡la z AI extrakce. To umoÅ¾Åˆuje frontend rozliÅ¡it:
- AI-extracted unknown field â†’ AI Insights (read-only)
- User-added unknown field â†’ Custom Parameters (editable)

**2. Frontend: `PackParametersSection.tsx` - Use `_ai_fields` for filtering**

```typescript
// PackParametersSection.tsx - categorizedParams useMemo
const aiFields = (parameters._ai_fields as unknown as string[] | undefined) ?? []

for (const [key, value] of Object.entries(parameters)) {
  // ...
  const isFromAi = aiFields.includes(key)

  // Skip unknown fields from AI extraction - they belong to AI Insights!
  if (isFromAi && category === 'custom') continue

  // User custom fields (NOT in aiFields) go to Custom category
  result[category].push([key, value, paramDef])
}

// PackParametersSection.tsx - aiNotes useMemo
const aiFields = (parameters._ai_fields as unknown as string[] | undefined) ?? []

for (const [key, value] of Object.entries(parameters)) {
  const category = getParamCategory(key)
  const isFromAi = aiFields.includes(key)

  // Include in AI Insights if:
  // - It's a known AI note key (whitelist), OR
  // - It's an unknown field that came from AI extraction
  const isUnknownFromAi = isFromAi && category === 'custom' && !isInternalField

  if (AI_NOTES_KEYS.has(key) || isUnknownFromAi) {
    notes.push({ key, value, label })
  }
}
```

**3. Frontend: `EditParametersModal.tsx` - Filter AI fields from edit**

```typescript
// EditParametersModal.tsx - useEffect for modal open
useEffect(() => {
  if (isOpen) {
    const stringified: Record<string, string> = {}
    // Get list of AI-extracted field names (not user-added custom fields)
    const aiFields = (initialParameters._ai_fields as unknown as string[] | undefined) ?? []

    for (const [key, value] of Object.entries(initialParameters)) {
      if (key.startsWith('_')) continue

      // Skip AI-extracted unknown fields - they belong to AI Insights
      // BUT keep user-added custom fields (they're NOT in _ai_fields array)
      const isAiField = aiFields.includes(key)
      const isKnownParam = Boolean(getParamDef(key))
      if (isAiField && !isKnownParam) continue

      stringified[key] = String(value ?? '')
    }
    setParameters(stringified)
  }
}, [isOpen, initialParameters])
```

**ProÄ toto funguje:**
- `_ai_fields` obsahuje pouze pole extrahovanÃ¡ AI
- User custom param "test" NENÃ v `_ai_fields` â†’ zobrazÃ­ se v editoru
- AI insight "usage_tips" JE v `_ai_fields` a nenÃ­ known param â†’ NEzobrazÃ­ se v editoru

---

##### TASK CHECKLIST

| Ãškol | Stav | Popis |
|------|------|-------|
| Backend: Add `_ai_fields` tracking | âœ… | `src/ai/service.py:216` - tracks AI-extracted field names |
| Frontend: Fix `categorizedParams` | âœ… | Uses `_ai_fields` to skip AI unknown fields from Custom |
| Frontend: Fix `aiNotes` useMemo | âœ… | Uses `_ai_fields` to include AI unknown fields in AI Insights |
| Frontend: Fix EditParametersModal load | âœ… | Uses `_ai_fields` to filter AI insights but keep user custom |
| Frontend: Fix EditParametersModal save | âœ… | Preserves `_ai_fields`, `_extracted_by` on save |
| Frontend: Fix button nesting DOM warning | âœ… | `CategorySection` restructured - button and dropdown are siblings |
| Styling AI Insights sekce | âœ… | Lightbulb icon, read-only display |
| Tests | âœ… | verify.sh passes, TypeScript OK |

---

##### PÅ˜ÃKLAD - JAK MÃ VYPADAT VÃSLEDEK

**Input (AI response):**
```json
{
  "cfg_scale": 7,
  "steps": 25,
  "sampler": "DPM++ 2M Karras",
  "usage_tips": "Best results with portrait",
  "compatibility": "Works with SD 1.5",
  "recommended_embeddings": ["EasyNegative", "BadHands"],
  "_extracted_by": "gemini"
}
```

**Display - PackParametersSection:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generation Settings                            [ğŸ¤– gemini] [Edit]â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âš™ï¸ Generation                                                    â”‚
â”‚   [CFG Scale: 7] [Steps: 25] [Sampler: DPM++ 2M Karras]         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ’¡ AI Insights (read-only)                                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ Usage Tips: Best results with portrait                  â”‚   â”‚
â”‚   â”‚ Compatibility: Works with SD 1.5                        â”‚   â”‚
â”‚   â”‚ Recommended Embeddings: EasyNegative â€¢ BadHands         â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ”§ Custom Parameters (prÃ¡zdnÃ© - uÅ¾ivatel nic nepÅ™idal)           â”‚
â”‚   No custom parameters.                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**EditParametersModal - Co se zobrazÃ­:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Edit Generation Parameters                                  [Ã—] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âš™ï¸ Generation                                                    â”‚
â”‚   CFG Scale: [7      ] [-][+]                                   â”‚
â”‚   Steps:     [25     ] [-][+]                                   â”‚
â”‚   Sampler:   [DPM++ 2M Karras    ]                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ”§ Custom (Add your own parameters)                              â”‚
â”‚   [Parameter name] [Value] [Type â–¼] [Category â–¼] [+ Add]        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â„¹ï¸ AI Insights are preserved but not editable here.              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                              [Cancel] [Save]                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**KlÃ­ÄovÃ©:** AI Insights (usage_tips, compatibility, recommended_embeddings) se NEZOBRAZUJÃ v edit modal, ale jsou ZACHOVÃNY pÅ™i uloÅ¾enÃ­!

---

##### RELATED FILES (ACTUAL CHANGES)

| Soubor | ZmÄ›na |
|--------|-------|
| `src/ai/service.py` | Added `_ai_fields` array to track AI-extracted field names |
| `PackParametersSection.tsx` | Uses `_ai_fields` in categorizedParams and aiNotes useMemo |
| `EditParametersModal.tsx` | Uses `_ai_fields` to filter AI unknown fields, fixed button nesting |

---

### Phase 2: Polish & More Tasks
**Goal:** Production-ready + additional tasks

- [ ] Frontend: AI Notes display (viz 8.1.8) â† VYSOKÃ PRIORITA
- [ ] Backend: Task priority configuration
- [ ] Backend: Advanced caching (TTL, invalidation)
- [ ] Backend: Retry logic
- [ ] Frontend: TaskPriorityConfig component
- [ ] Frontend: Provider status polling
- [ ] Task: Description translation (+ AI Notes pÅ™eklad)
- [ ] Task: Auto-tagging
- [ ] Documentation

### Phase 3: Advanced Tasks
**Goal:** Complex AI tasks

- [ ] Task: Workflow generation
- [ ] Task: Model compatibility analysis
- [ ] Task: Config migration
- [ ] Task: Preview analysis (multimodal)
- [ ] Performance optimization
- [ ] Metrics & logging dashboard

---

## 9. Resolved Questions âœ…

| OtÃ¡zka | RozhodnutÃ­ |
|--------|------------|
| **Settings storage** | `settings.json` (souÄÃ¡st hlavnÃ­ho configu) |
| **Cache location** | `~/.synapse/store/data/cache/ai/` |
| **Custom models** | Defaults z benchmarku + moÅ¾nost zadat vlastnÃ­ |
| **Offline mode** | Ollama je offline provider, pak rule-based fallback |
| **RuÄnÃ­ extrakce z UI** | âŒ NECHCEME - extrakce je POUZE automatickÃ¡ pÅ™i importu |

### OtevÅ™enÃ© otÃ¡zky

| OtÃ¡zka | Status |
|--------|--------|
| Rate limiting pro cloud? | â“ ProzatÃ­m nepotÅ™ebujeme |
| Avatar priorita? | â“ Future vision, pozdÄ›ji |

---

## 10. Logging & Debugging

### 10.1 Log Categories

```python
# Logging prefixes for AI operations
LOG_PREFIX = "[ai-service]"

# Log levels by operation type
LOGGING_CONFIG = {
    "provider_detection": "INFO",      # Which providers found
    "task_execution": "INFO",          # Task started, provider used
    "fallback": "WARNING",             # Provider failed, trying next
    "cache_hit": "DEBUG",              # Cache used
    "cache_miss": "DEBUG",             # Cache miss, calling AI
    "response_parse": "DEBUG",         # JSON parsing details
    "timeout": "WARNING",              # Provider timeout
    "error": "ERROR",                  # Unrecoverable errors
}
```

### 10.2 Log Format Examples

```
[ai-service] Task: parameter_extraction, Provider: ollama (qwen2.5:14b)
[ai-service] Response received in 2.8s, parsing JSON...
[ai-service] Extracted 12 parameters: cfg_scale, steps, sampler, ...
[ai-service] Result cached with key: a1b2c3d4e5f6

[ai-service] WARNING: Provider ollama failed: timeout after 60s
[ai-service] Fallback to gemini (gemini-3-pro)
[ai-service] Response received in 18.2s

[ai-service] Cache hit for key: a1b2c3d4e5f6 (age: 2d 4h)
```

### 10.3 Debug Mode

V Settings moÅ¾nost zapnout verbose logging:
- Logovat celÃ½ prompt (mÅ¯Å¾e bÃ½t velkÃ½!)
- Logovat raw response pÅ™ed parsovÃ¡nÃ­m
- Logovat cache operations

---

## 11. Testing Strategy

### 11.1 Unit Tests

```python
# tests/unit/ai/test_providers.py
class TestOllamaProvider:
    def test_detect_availability(self): ...
    def test_execute_simple_prompt(self): ...
    def test_parse_response_with_fences(self): ...
    def test_timeout_handling(self): ...

class TestGeminiProvider:
    def test_detect_availability(self): ...
    def test_model_selection(self): ...
    def test_preview_features_required(self): ...

class TestClaudeProvider:
    def test_detect_availability(self): ...
    def test_print_flag_usage(self): ...
```

### 11.2 Integration Tests

```python
# tests/integration/ai/test_parameter_extraction.py
class TestParameterExtractionE2E:
    """
    End-to-end tests using real providers (skipped if not available).
    """

    @pytest.mark.skipif(not ollama_available(), reason="Ollama not running")
    def test_extraction_ollama_real(self): ...

    @pytest.mark.skipif(not gemini_available(), reason="Gemini CLI not installed")
    def test_extraction_gemini_real(self): ...

    def test_fallback_chain(self): ...
    def test_cache_hit(self): ...
    def test_all_providers_fail_uses_rule_based(self): ...
```

### 11.3 Benchmark Tests

```python
# tests/benchmark/ai/test_extraction_quality.py
class TestExtractionQuality:
    """
    Quality benchmarks from ai_extraction_spec.md test suite.
    13 diverse CivitAI descriptions.
    """

    BENCHMARK_DESCRIPTIONS = [
        ("GhostMix V2.0", "...", {"expected_keys": 9}),
        ("MeinaMix", "...", {"expected_keys": 14}),
        ("SynthwavePunk", "...", {"expected_keys": 7}),  # Minimal
        # ... 10 more
    ]

    def test_extraction_coverage(self, provider): ...
    def test_snake_case_compliance(self, result): ...
    def test_numeric_typing(self, result): ...
    def test_no_placeholder_values(self, result): ...
    def test_no_hallucinated_base_model(self, result): ...
```

### 11.4 Mock Provider for Development

```python
# src/ai/providers/mock.py
class MockProvider(AIProviderBase):
    """
    Mock provider for development and testing.
    Returns predefined responses without calling external services.
    """

    def __init__(self, responses: Dict[str, str]):
        self.responses = responses
        self.call_count = 0

    async def execute(self, prompt: str, **kwargs) -> str:
        self.call_count += 1
        # Return based on prompt hash or content matching
        return self.responses.get(hash(prompt), "{}")
```

---

## 12. Future Vision: AI Assistant Avatar ğŸš€

### 12.1 Koncept

InteraktivnÃ­ AI avatar v pravÃ©m dolnÃ­m rohu aplikace, kterÃ½:
- **MluvÃ­** - TTS (text-to-speech) pro odpovÄ›di
- **PoslouchÃ¡** - STT (speech-to-text) pro pÅ™Ã­kazy
- **PomÃ¡hÃ¡** - kontextovÃ¡ nÃ¡povÄ›da, prÅ¯vodce sloÅ¾itÃ½mi Ãºkoly
- **Analyzuje** - vysvÄ›tluje co vidÃ­ v UI, doporuÄuje akce

### 12.2 Use Cases

| ScÃ©nÃ¡Å™ | PÅ™Ã­klad interakce |
|--------|-------------------|
| **Onboarding** | "VÃ­tej v Synapse! ChceÅ¡ ti ukÃ¡Å¾u jak importovat prvnÃ­ model?" |
| **Troubleshooting** | "VidÃ­m, Å¾e mÃ¡Å¡ 3 unresolved dependencies. ChceÅ¡ je stÃ¡hnout?" |
| **DoporuÄenÃ­** | "Pro tento LoRA bych doporuÄil CFG 7 a 25 krokÅ¯." |
| **Workflow help** | "PotÅ™ebujeÅ¡ vytvoÅ™it ComfyUI workflow? Å˜ekni mi co chceÅ¡ generovat." |
| **Voice commands** | "Hej Synapse, importuj model z tÃ©to URL." |

### 12.3 TechnickÃ¡ architektura (draft)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AI Assistant Avatar                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   STT    â”‚â”€â”€â”€â–¶â”‚  Intent  â”‚â”€â”€â”€â–¶â”‚    AI    â”‚â”€â”€â”€â–¶â”‚   TTS    â”‚  â”‚
â”‚  â”‚ (Whisper)â”‚    â”‚  Parser  â”‚    â”‚ Provider â”‚    â”‚(Coqui/11)â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â–²                               â”‚                         â”‚
â”‚       â”‚                               â–¼                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚   Mic    â”‚                  â”‚  UI Actions  â”‚                 â”‚
â”‚  â”‚  Input   â”‚                  â”‚  (mutations) â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Komponenty:**
- **STT:** Whisper (lokÃ¡lnÃ­) nebo cloud API
- **Intent Parser:** RozpoznÃ¡nÃ­ pÅ™Ã­kazÅ¯ vs. konverzace
- **AI Provider:** VyuÅ¾itÃ­ existujÃ­cÃ­ AI infrastruktury
- **TTS:** Coqui TTS (lokÃ¡lnÃ­, open-source) nebo ElevenLabs (premium)
- **Avatar UI:** AnimovanÃ½ avatar (moÅ¾nÃ¡ AI-generated face)

### 12.4 Implementation Phases (Future)

1. **Phase A:** Text chat bubble (no voice)
2. **Phase B:** TTS output (avatar mluvÃ­)
3. **Phase C:** STT input (voice commands)
4. **Phase D:** Context awareness (vÃ­ co uÅ¾ivatel dÄ›lÃ¡)
5. **Phase E:** Proactive suggestions (sÃ¡m nabÃ­zÃ­ pomoc)

### 12.5 Future Vision: AI Image Generation ğŸ¨

Gemini CLI podporuje generovÃ¡nÃ­ obrÃ¡zkÅ¯, coÅ¾ otevÃ­rÃ¡ dalÅ¡Ã­ moÅ¾nosti pro Synapse:

#### DostupnÃ© nÃ¡stroje

| NÃ¡stroj | Typ | PÅ™Ã­kaz | PoznÃ¡mka |
|---------|-----|--------|----------|
| **Gemini CLI + MCP** | Cloud | MCP server (Imagen, Veo) | IntegrovÃ¡no v Gemini CLI |
| **gemini-imagen** | Cloud | `pip install gemini-imagen` | SamostatnÃ½ CLI tool |
| **Imagen 4.0** | Cloud | Via Gemini API | NejnovÄ›jÅ¡Ã­ model |

#### Modely pro image generation

| Model | Kvalita | Rychlost | PoznÃ¡mka |
|-------|---------|----------|----------|
| `gemini-2.5-flash-image` | StÅ™ednÃ­ | RychlÃ½ | Pro rychlÃ© nÃ¡hledy |
| `gemini-3-pro-image-preview` | VysokÃ¡ | PomalejÅ¡Ã­ | Pro kvalitnÃ­ vÃ½stupy |
| `imagen-4.0` | NejvyÅ¡Å¡Ã­ | StÅ™ednÃ­ | DedikovanÃ½ image model |

#### PotenciÃ¡lnÃ­ use cases pro Synapse

| Funkce | Popis |
|--------|-------|
| **Thumbnail generation** | AutomatickÃ© generovÃ¡nÃ­ nÃ¡hledÅ¯ pro packy bez preview |
| **Preview suggestion** | "Jak by mohl vypadat vÃ½stup s tÄ›mito parametry?" |
| **Style transfer** | UkÃ¡zka jak by LoRA zmÄ›nilo styl obrÃ¡zku |
| **Missing preview** | DoplnÄ›nÃ­ chybÄ›jÃ­cÃ­ch preview pro modely |
| **Avatar face** | GenerovÃ¡nÃ­ tvÃ¡Å™e pro AI Assistant Avatar |

#### PÅ™Ã­klad pouÅ¾itÃ­

```bash
# Standalone CLI
pip install gemini-imagen
gemini-imagen "preview image for anime style LoRA, high quality"

# Nebo pÅ™es Gemini CLI s MCP
gemini --tool imagen "generate preview thumbnail"
```

> âš ï¸ **PoznÃ¡mka:** Image generation je resource-intensive a mÃ¡ rate limity.
> VhodnÃ© spÃ­Å¡e pro on-demand funkce neÅ¾ automatickÃ© zpracovÃ¡nÃ­.

### 12.6 Agent Tool Calling ğŸ”§

**ProblÃ©m:** S rostoucÃ­m poÄtem AI funkcÃ­ (extrakce parametrÅ¯, dependency resolver, workflow suggestions, auto-tagging...) by vznikla "kupa AI tlaÄÃ­tek" rozhÃ¡zenÃ½ch po UI.

**Å˜eÅ¡enÃ­:** Agent s tool calling - jednotnÃ½ vstupnÃ­ bod, kterÃ½ znÃ¡ dostupnÃ© funkce a umÃ­ je volat.

#### Architektura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Agent Tool Calling                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  User Input (text/voice)                                        â”‚
â”‚       â”‚                                                         â”‚
â”‚       â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  AI Agent (gemini/claude)                                 â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚  System prompt:                                     â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  "You are Synapse assistant. You have these tools:" â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  - extract_parameters(pack_name)                    â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  - resolve_dependencies(pack_name)                  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  - suggest_workflow(pack_name, style)               â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  - translate_description(pack_name, target_lang)    â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  - auto_tag(pack_name)                              â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  - analyze_compatibility(lora, checkpoint)          â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚                                                         â”‚
â”‚       â–¼                                                         â”‚
â”‚  Tool Call: extract_parameters("GhostMix")                      â”‚
â”‚       â”‚                                                         â”‚
â”‚       â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Backend API                                              â”‚  â”‚
â”‚  â”‚  POST /api/ai/extract { pack_name: "GhostMix" }          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚                                                         â”‚
â”‚       â–¼                                                         â”‚
â”‚  Agent Response: "Extrahoval jsem 12 parametrÅ¯ pro GhostMix..." â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### DostupnÃ© Tools (plÃ¡novanÃ©)

| Tool | Popis | API Endpoint |
|------|-------|--------------|
| `extract_parameters` | Re-extrakce parametrÅ¯ pro starÅ¡Ã­ packy | `POST /api/ai/extract` |
| `resolve_dependencies` | NajÃ­t a navrhnout chybÄ›jÃ­cÃ­ zÃ¡vislosti | `POST /api/ai/resolve-deps` |
| `suggest_workflow` | Navrhnout ComfyUI workflow | `POST /api/ai/suggest-workflow` |
| `translate_description` | PÅ™eloÅ¾it popis do jinÃ©ho jazyka | `POST /api/ai/translate` |
| `auto_tag` | AutomatickÃ© tagovÃ¡nÃ­ packu | `POST /api/ai/auto-tag` |
| `analyze_compatibility` | AnalÃ½za kompatibility LoRA + Checkpoint | `POST /api/ai/compatibility` |

#### PÅ™Ã­klady interakcÃ­

```
User: "Extrahuj parametry pro GhostMix, mÃ¡ starÅ¡Ã­ verzi bez AI dat"
Agent: [calls extract_parameters("GhostMix")]
Agent: "Hotovo! Extrahoval jsem 12 parametrÅ¯: CFG 7, Steps 25, Sampler DPM++..."

User: "Tento LoRA mi hlÃ¡sÃ­ chybÄ›jÃ­cÃ­ zÃ¡vislosti, pomoz mi"
Agent: [calls resolve_dependencies("MyLoRA")]
Agent: "NaÅ¡el jsem 2 chybÄ›jÃ­cÃ­ zÃ¡vislosti: anime_base.safetensors a EasyNegative..."

User: "Jak by vypadal workflow pro portrait fotky s tÃ­mto LoRA?"
Agent: [calls suggest_workflow("MyLoRA", "portrait")]
Agent: "Navrhuji tento workflow: KSampler â†’ VAE Decode â†’ ..."
```

#### VÃ½hody oproti jednotlivÃ½m tlaÄÃ­tkÅ¯m

1. **JednotnÃ½ vstupnÃ­ bod** - uÅ¾ivatel se nemusÃ­ uÄit kde jsou kterÃ¡ tlaÄÃ­tka
2. **Kontext-aware** - agent vÃ­ na jakÃ©m packu uÅ¾ivatel pracuje
3. **KombinovatelnÃ©** - agent mÅ¯Å¾e volat vÃ­ce tools najednou
4. **Natural language** - uÅ¾ivatel popisuje co chce, ne jak to udÄ›lat
5. **RozÅ¡iÅ™itelnÃ©** - pÅ™idÃ¡nÃ­ novÃ©ho tool = jen registrace v systÃ©mu

#### Implementation Notes

- Agent bude vyuÅ¾Ã­vat existujÃ­cÃ­ AI infrastrukturu (providers, fallback chain)
- Tools budou implementovÃ¡ny jako API endpointy
- Frontend: chat bubble komponenta v pravÃ©m dolnÃ­m rohu
- Backend: tool registry s JSON schema pro kaÅ¾dÃ½ tool

---

> âš ï¸ **PoznÃ¡mka:** Toto je dlouhodobÃ¡ vize. Implementace zÃ¡visÃ­ na:
> - Dostupnosti kvalitnÃ­ch lokÃ¡lnÃ­ch TTS/STT modelÅ¯
> - UÅ¾ivatelskÃ© poptÃ¡vce
> - KomplexitÄ› integrace s UI

---

## 13. References

### Dokumentace
- [AI Extraction Spec](./ai_extraction_spec.md) - **KRITICKÃ‰:** VÃ½sledky benchmarku, prompt V2, best practices
- [Parameter Extractor](../src/utils/parameter_extractor.py) - StÃ¡vajÃ­cÃ­ rule-based implementace

### Provider dokumentace
- [Ollama Documentation](https://ollama.com/docs)
- [Gemini CLI GitHub](https://github.com/google-gemini/gemini-cli)
- [Gemini Models](https://ai.google.dev/gemini-api/docs/models)
- [Claude Code](https://claude.ai/claude-code)

### Future (Avatar)
- [Coqui TTS](https://github.com/coqui-ai/TTS) - Open-source TTS
- [Whisper](https://github.com/openai/whisper) - Open-source STT
- [ElevenLabs](https://elevenlabs.io/) - Premium TTS API

---

*Last Updated: 2026-02-03 (Agent Tool Calling vision added)*

---

## 14. Logging Summary

### 14.1 Logging je kompletnÃ­ v celÃ©m toolchainu

| Modul | Loguje | PÅ™Ã­klad |
|-------|--------|---------|
| `service.py` | Provider chain, fallback, cache | `[ai-service] Task: parameter_extraction, Provider chain: ollama â†’ gemini â†’ claude` |
| `ollama.py` | Execute, server start/stop | `[ai-service] Starting ollama serve...` / `[ai-service] Stopping ollama serve (freeing VRAM)` |
| `gemini.py` | Execute, response | `[ai-service] Task: executing, Provider: gemini (gemini-3-pro-preview)` |
| `claude.py` | Execute, response | `[ai-service] Task: executing, Provider: claude (claude-sonnet-4)` |
| `cache.py` | Hit/miss, cleanup | `[ai-service] Cache hit for key: abc123 (age: 2.1d)` |

### 14.2 OvÄ›Å™enÃ­ logÅ¯ z reÃ¡lnÃ©ho bÄ›hu

```
INFO  [ai-service] Task: parameter_extraction, Provider chain: ollama â†’ gemini â†’ claude
INFO  [ai-service] Task: executing, Provider: ollama (qwen2.5:14b)
INFO  [ai-service] Retry 1/2 for ollama
INFO  [ai-service] Retry 2/2 for ollama
WARNING [ai-service] Fallback: ollama failed, trying next...
INFO  [ai-service] Task: executing, Provider: gemini (gemini-3-pro-preview)
DEBUG [ai-service] Raw response length: 53
INFO  [ai-service] Extracted 3 parameters
INFO  [ai-service] Response received in 11.7s, extracted 3 parameters
DEBUG [ai-service] Result cached with key: 8b6abd297254a584
```

**Ollama JE volÃ¡na** - logy potvrzujÃ­ retry logiku, pak fallback na Gemini.
